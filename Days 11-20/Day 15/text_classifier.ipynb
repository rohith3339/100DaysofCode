{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text Classification using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Chaitanya\n",
      "[nltk_data]     V\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as numpy\n",
    "import nltk\n",
    "import pickle\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset (Original Source of Dataset is \"http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\")\n",
    "reviews = load_files(\"txt_sentoken/\") # load files function should be used only for small datasets.\n",
    "x,y = reviews.data,reviews.target # Since neg folder is first in text_sentoken, it's class is 0 and for pos its class is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing as pickle files\n",
    "with open('x.pickle','wb') as f:\n",
    "    pickle.dump(x,f)\n",
    "\n",
    "with open('y.pickle','wb') as f:\n",
    "    pickle.dump(y,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickling the dataset\n",
    "with open('x.pickle','rb') as f:\n",
    "    x = pickle.load(f)\n",
    "\n",
    "with open('y.pickle','rb') as f:\n",
    "    y = pickle.load(f)\n",
    "    \n",
    "# print(x[1:2],y[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the corpus by pre-processing the dataset\n",
    "corpus = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    review = re.sub(r'\\\\n','',str(x[i])) #Replacing all \\n (new-line tags which are created during unpickling) with a single space\n",
    "    review = re.sub(r'\\W',' ',review) # Replacing special characters with a single space.\n",
    "    review = review.lower() # Lowercasing if any uppercase letters\n",
    "    review = re.sub(r'\\s+[a-z]\\s+',' ',review) # Replacing single alphabets surrounded by single space on both sides with a single space\n",
    "    review = re.sub(r'^b\\s+',' ',review) # Replacing single alphabets following a single space at start of the sentence with a single space\n",
    "    review = re.sub(r'\\s+b$',' ',review) # Replacing single alphabets followed a single space at end of the sentence with a single space\n",
    "    review = re.sub(r'\\s+',' ',review) # Replacing mutliple consecutive spaces with a single space\n",
    "    corpus.append(review)\n",
    "\n",
    "# print(corpus[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Bag of Words Model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=2000,min_df=3,max_df=0.6,stop_words=stopwords.words(\"english\")) \n",
    "# max_features=2000 means we are selecting top 2000 words as our desired features\n",
    "# min_df = 3 (implies 3 sentences out of all sentences in corpuse) implies if a word is in less than 3 sentences of our dataset it will be excluded immediately\n",
    "# max_df = 0.6(implies 60% of whole corpus) implies that if any word is seen more than 60% of time in the whole corpus it will be excluded as it might be a common word\n",
    "# stop_words = stopwords.words(\"english\") implies removal of english based stopwords from the whole corpus\n",
    "X = vectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Model using already existing Binary Bag of Words Model\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer =  TfidfTransformer()\n",
    "X = transformer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting whole corpus into two parts\n",
    "# Train dataset and Test dataset\n",
    "# Which means we will train our model on train dataset first.\n",
    "# And then validate its performance, accuracy using test dataset.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "data_train,data_test,label_train,label_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "# X = Our processed,organized data.\n",
    "# Y = Labels\n",
    "# test_size=0.2 means test dataset is 20% of total corpus => train dataset is 80% of total corpus\n",
    "# random_state=0 implies we are not choosing randomly. We can change it to 1 to make multiple test datasets and train datasets depending on your understanding.\n",
    "# Training data is stored in data_train\n",
    "# Testing data is stored in data_test\n",
    "# Training Labels are stored in label_train\n",
    "# Testing Labels are stored in label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Logistic Regression Algorithm (Binary Classification) to fit our model\n",
    "# Logistic Regression is being used to find optimal weights for each document in corpus to normalize label values betwwen 0 or 1.\n",
    "# Equation of Logistic Regression is:\n",
    "# \n",
    "# ln(y/y-1) = a+bx₁+cx₂+……..+dx₂₀₀₀\n",
    "# \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(data_train,label_train) # Inputting train data and labels to Logistic Regression Classifier\n",
    "# Trained our classifier on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, evaluating our classifier accuracy on test dataset\n",
    "label_pred = classifier.predict(data_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm =  confusion_matrix(label_test,label_pred)\n",
    "# Checking between actual labels and predicted labels on test dataset\n",
    "# This gives us a confusion matrix as follows:\n",
    "\n",
    "#-- -------------------------------------\n",
    "# ░ |        0        |        1        |\n",
    "#----------------------------------------\n",
    "# 0 | True Negatives  | False Negatives |\n",
    "#---|------------------------------------\n",
    "# 1 | False Positives | True Positives  |\n",
    "#----------------------------------------\n",
    "\n",
    "# Where True Negatives means both actual and model predicted labels as negative (in this case negative = 0) \n",
    "# Where True Positives means both actual and model predicted labels as positive (in this case positive = 1)\n",
    "# Above both are correct predictions and we need more of them.\n",
    "\n",
    "# Below both are incorrect predictions and we need only few or almost none of them.\n",
    "# Where False Negatives means actual label are positives, but our model predicted them as negatives.\n",
    "# Where False Positives means actual label are negatives, but our model predicted them as positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[169  39]\n",
      " [ 22 170]]\n"
     ]
    }
   ],
   "source": [
    "# So, let's see how our model fared.\n",
    "print(cm)\n",
    "\n",
    "# It shows the result matrix as\n",
    "\n",
    "#----------------------------------------------------\n",
    "# ░ |           0           |           1           |\n",
    "#----------------------------------------------------\n",
    "# 0 | 169 (True Negatives)  |  39 (False Negatives) |\n",
    "#---|------------------------------------------------\n",
    "# 1 |  22 (False Positives) | 170 (True Positives)  |\n",
    "#----------------------------------------------------\n",
    "\n",
    "accuracy = (cm[0][0] + cm[1][1])/4\n",
    "# So, out of 400 labelled data, our model predicted labels for 169+170=339 data correctly.\n",
    "# Which means our accuracy is 339/400 = 0.8475\n",
    "# Our Prediction Accuracy is 84.75% as of now using non-randomness of 20% test, 80% train data with logistic regression model.\n",
    "# It can be made better by tweaking the parameters of CountVectorizer, Tfidftransformer. \n",
    "# But, still as a starter this can be called good accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
